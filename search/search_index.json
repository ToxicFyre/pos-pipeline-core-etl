{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"POS Core ETL","text":"<p>A comprehensive Python package for Point of Sale (POS) data processing, forecasting, and quality assurance.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>ETL Pipeline: Extract, transform, and load POS payment and sales data</li> <li>Time Series Forecasting: Generate ARIMA-based forecasts for payment metrics</li> <li>Quality Assurance: Automated data validation and anomaly detection</li> <li>Multi-Branch Support: Handle multiple sucursales (branches) with code window tracking</li> <li>Incremental Processing: Smart date range chunking and existing data discovery</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from pathlib import Path\nfrom pos_core.etl import PaymentsETLConfig, build_payments_dataset\nfrom pos_core.forecasting import ForecastConfig, run_payments_forecast\n\n# Configure and run ETL\nconfig = PaymentsETLConfig.from_data_root(Path(\"data\"))\npayments = build_payments_dataset(\"2025-01-01\", \"2025-01-31\", config)\n\n# Generate forecast\nforecast = run_payments_forecast(payments, ForecastConfig(horizon_days=7))\nprint(forecast.forecast.head())\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pos-core-etl\n</code></pre> <p>For development:</p> <pre><code>pip install -e .[dev]\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>User Guide - Installation, configuration, and usage</li> <li>API Reference - Complete API documentation</li> <li>Examples - Runnable example scripts</li> </ul>"},{"location":"#license","title":"License","text":"<p>MIT License - see LICENSE file for details.</p>"},{"location":"api-reference/etl/","title":"ETL API Reference","text":""},{"location":"api-reference/etl/#paymentsetlconfig","title":"<code>PaymentsETLConfig</code>","text":"<p>Configuration dataclass for payments ETL pipeline.</p>"},{"location":"api-reference/etl/#attributes","title":"Attributes","text":"<ul> <li><code>paths</code> (PaymentsPaths): All filesystem paths used by the pipeline</li> <li><code>chunk_size_days</code> (int): Maximum number of days per HTTP request chunk (default: 180)</li> <li><code>excluded_branches</code> (List[str]): List of branch names to exclude from processing (default: [\"CEDIS\"])</li> </ul>"},{"location":"api-reference/etl/#methods","title":"Methods","text":""},{"location":"api-reference/etl/#from_data_root","title":"<code>from_data_root()</code>","text":"<p>Build a default config given a data_root.</p> <pre><code>config = PaymentsETLConfig.from_data_root(\n    data_root=Path(\"data\"),\n    sucursales_json=Path(\"utils/sucursales.json\"),\n    chunk_size_days=180\n)\n</code></pre>"},{"location":"api-reference/etl/#paymentspaths","title":"<code>PaymentsPaths</code>","text":"<p>Path configuration for ETL stages.</p>"},{"location":"api-reference/etl/#attributes_1","title":"Attributes","text":"<ul> <li><code>raw_payments</code> (Path): Directory for raw payment Excel files</li> <li><code>clean_payments</code> (Path): Directory for cleaned payment CSV files</li> <li><code>proc_payments</code> (Path): Directory for processed/aggregated payment data</li> <li><code>sucursales_json</code> (Path): Path to sucursales.json configuration file</li> </ul>"},{"location":"api-reference/etl/#build_payments_dataset","title":"<code>build_payments_dataset()</code>","text":"<p>Main orchestration function for payments ETL.</p>"},{"location":"api-reference/etl/#signature","title":"Signature","text":"<pre><code>def build_payments_dataset(\n    start_date: str,\n    end_date: str,\n    config: PaymentsETLConfig,\n    branches: Optional[List[str]] = None,\n    steps: Optional[List[str]] = None,\n) -&gt; pd.DataFrame\n</code></pre>"},{"location":"api-reference/etl/#parameters","title":"Parameters","text":"<ul> <li><code>start_date</code> (str): Start date in YYYY-MM-DD format (inclusive)</li> <li><code>end_date</code> (str): End date in YYYY-MM-DD format (inclusive)</li> <li><code>config</code> (PaymentsETLConfig): Configuration instance</li> <li><code>branches</code> (Optional[List[str]]): List of branch names to process. If None, processes all branches.</li> <li><code>steps</code> (Optional[List[str]]): List of steps to execute. Valid steps: \"extract\", \"transform\", \"aggregate\". If None, executes all steps.</li> </ul>"},{"location":"api-reference/etl/#returns","title":"Returns","text":"<p>DataFrame containing the aggregated payments data (one row per sucursal + fecha).</p>"},{"location":"api-reference/etl/#raises","title":"Raises","text":"<ul> <li><code>ConfigError</code>: If invalid step names are provided</li> <li><code>FileNotFoundError</code>: If the aggregated file is expected but missing</li> </ul>"},{"location":"api-reference/etl/#example","title":"Example","text":"<pre><code>from pathlib import Path\nfrom pos_core.etl import PaymentsETLConfig, build_payments_dataset\n\nconfig = PaymentsETLConfig.from_data_root(Path(\"data\"))\ndf = build_payments_dataset(\"2023-01-01\", \"2023-12-31\", config)\n</code></pre>"},{"location":"api-reference/exceptions/","title":"Exceptions API Reference","text":"<p>The package defines custom exceptions that are part of the public API. All exceptions inherit from <code>PosAPIError</code> for easy catching.</p>"},{"location":"api-reference/exceptions/#posapierror","title":"<code>PosAPIError</code>","text":"<p>Base exception for all POS Core ETL errors.</p> <p>This is the base class for all domain-specific exceptions in the package. Users can catch this exception to handle any POS Core ETL error.</p> <pre><code>from pos_core.exceptions import PosAPIError\n\ntry:\n    # Some POS Core ETL operation\n    pass\nexcept PosAPIError as e:\n    # Handle any POS Core ETL error\n    print(f\"POS Core ETL error: {e}\")\n</code></pre>"},{"location":"api-reference/exceptions/#configerror","title":"<code>ConfigError</code>","text":"<p>Raised when there is a configuration error.</p> <p>This exception is raised when: - Invalid configuration values are provided - Required configuration is missing - Configuration files cannot be loaded or parsed</p> <pre><code>from pos_core.exceptions import ConfigError\n\ntry:\n    # Configuration operation\n    pass\nexcept ConfigError as e:\n    # Handle configuration error\n    print(f\"Configuration error: {e}\")\n</code></pre>"},{"location":"api-reference/exceptions/#dataqualityerror","title":"<code>DataQualityError</code>","text":"<p>Raised when data quality checks fail.</p> <p>This exception is raised when: - Required columns are missing from input data - Data validation fails - Data quality checks detect critical issues</p> <pre><code>from pos_core.exceptions import DataQualityError\n\ntry:\n    # Data quality operation\n    pass\nexcept DataQualityError as e:\n    # Handle data quality error\n    print(f\"Data quality error: {e}\")\n</code></pre>"},{"location":"api-reference/forecasting/","title":"Forecasting API Reference","text":""},{"location":"api-reference/forecasting/#forecastconfig","title":"<code>ForecastConfig</code>","text":"<p>Configuration for payments forecasting.</p>"},{"location":"api-reference/forecasting/#attributes","title":"Attributes","text":"<ul> <li><code>horizon_days</code> (int): Number of days ahead to forecast (default: 7)</li> <li><code>metrics</code> (List[str]): List of metrics to forecast (default: cash, credit, debit, total)</li> <li><code>branches</code> (Optional[List[str]]): List of branch names to forecast. If None, infers from payments_df.</li> </ul>"},{"location":"api-reference/forecasting/#example","title":"Example","text":"<pre><code>from pos_core.forecasting import ForecastConfig\n\nconfig = ForecastConfig(\n    horizon_days=14,\n    metrics=[\"ingreso_efectivo\", \"ingreso_total\"],\n    branches=[\"Banana\", \"Queen\"]\n)\n</code></pre>"},{"location":"api-reference/forecasting/#forecastresult","title":"<code>ForecastResult</code>","text":"<p>Result dataclass containing forecast DataFrame, deposit schedule, and metadata.</p>"},{"location":"api-reference/forecasting/#attributes_1","title":"Attributes","text":"<ul> <li><code>forecast</code> (pd.DataFrame): DataFrame with columns: sucursal, fecha, metric, valor</li> <li><code>deposit_schedule</code> (pd.DataFrame): DataFrame with cash-flow deposit schedule</li> <li><code>metadata</code> (Dict[str, object]): Dictionary with additional metadata</li> </ul>"},{"location":"api-reference/forecasting/#metadata-keys","title":"Metadata Keys","text":"<ul> <li><code>branches</code>: List of branches forecasted</li> <li><code>metrics</code>: List of metrics forecasted</li> <li><code>horizon_days</code>: Number of days forecasted</li> <li><code>last_historical_date</code>: Last date in historical data</li> <li><code>successful_forecasts</code>: Number of successful forecasts</li> <li><code>failed_forecasts</code>: Number of failed forecasts</li> </ul>"},{"location":"api-reference/forecasting/#run_payments_forecast","title":"<code>run_payments_forecast()</code>","text":"<p>Main forecasting function.</p>"},{"location":"api-reference/forecasting/#signature","title":"Signature","text":"<pre><code>def run_payments_forecast(\n    payments_df: pd.DataFrame,\n    config: Optional[ForecastConfig] = None,\n) -&gt; ForecastResult\n</code></pre>"},{"location":"api-reference/forecasting/#parameters","title":"Parameters","text":"<ul> <li><code>payments_df</code> (pd.DataFrame): Aggregated payments data, typically the output of the ETL step. Expected columns include at least:</li> <li><code>sucursal</code> (branch name)</li> <li><code>fecha</code> (date or datetime)</li> <li>the metrics in config.metrics (e.g. ingreso_efectivo, ingreso_credito, ...)</li> <li><code>config</code> (Optional[ForecastConfig]): ForecastConfig for horizon, metrics, and branches. If None, uses defaults.</li> </ul>"},{"location":"api-reference/forecasting/#returns","title":"Returns","text":"<p>ForecastResult containing: - <code>forecast</code>: per-branch, per-metric predictions for the next horizon_days - <code>deposit_schedule</code>: computed cash-flow deposit schedule - <code>metadata</code>: additional information about the forecast</p>"},{"location":"api-reference/forecasting/#raises","title":"Raises","text":"<ul> <li><code>DataQualityError</code>: If required columns are missing, or no forecasts are generated.</li> </ul>"},{"location":"api-reference/forecasting/#example_1","title":"Example","text":"<pre><code>from pos_core.forecasting import ForecastConfig, run_payments_forecast\n\nconfig = ForecastConfig(horizon_days=7)\nresult = run_payments_forecast(payments_df, config=config)\n\nprint(result.forecast.head())\nprint(result.deposit_schedule)\n</code></pre>"},{"location":"api-reference/qa/","title":"QA API Reference","text":""},{"location":"api-reference/qa/#paymentsqaresult","title":"<code>PaymentsQAResult</code>","text":"<p>Result dataclass with QA summary and detailed findings.</p>"},{"location":"api-reference/qa/#attributes","title":"Attributes","text":"<ul> <li><code>summary</code> (dict): Dictionary with summary statistics and counts</li> <li><code>missing_days</code> (pd.DataFrame | None): DataFrame with missing days per sucursal, or None if none found</li> <li><code>duplicate_days</code> (pd.DataFrame | None): DataFrame with duplicate (sucursal, fecha) rows, or None if none found</li> <li><code>zscore_anomalies</code> (pd.DataFrame | None): DataFrame with z-score anomalies, or None if none found</li> <li><code>zero_method_flags</code> (pd.DataFrame | None): DataFrame with rows where tickets &gt; 0 but payment methods are zero, or None if none found</li> </ul>"},{"location":"api-reference/qa/#summary-keys","title":"Summary Keys","text":"<ul> <li><code>total_rows</code>: Total number of rows in the dataset</li> <li><code>total_sucursales</code>: Number of unique branches</li> <li><code>min_fecha</code>: Minimum date in the dataset</li> <li><code>max_fecha</code>: Maximum date in the dataset</li> <li><code>has_missing_days</code>: Boolean indicating if missing days were found</li> <li><code>has_duplicates</code>: Boolean indicating if duplicates were found</li> <li><code>has_zscore_anomalies</code>: Boolean indicating if z-score anomalies were found</li> <li><code>has_zero_method_flags</code>: Boolean indicating if zero method flags were found</li> <li><code>missing_days_count</code>: Number of missing days</li> <li><code>duplicate_days_count</code>: Number of duplicate days</li> <li><code>zscore_anomalies_count</code>: Number of z-score anomalies</li> <li><code>zero_method_flags_count</code>: Number of zero method flags</li> <li><code>schema_errors</code>: List of schema validation errors</li> </ul>"},{"location":"api-reference/qa/#run_payments_qa","title":"<code>run_payments_qa()</code>","text":"<p>Main QA function for data validation.</p>"},{"location":"api-reference/qa/#signature","title":"Signature","text":"<pre><code>def run_payments_qa(\n    payments_df: pd.DataFrame,\n    level: int = 4,\n) -&gt; PaymentsQAResult\n</code></pre>"},{"location":"api-reference/qa/#parameters","title":"Parameters","text":"<ul> <li><code>payments_df</code> (pd.DataFrame): Aggregated payments data, typically the output of the ETL step. Expected columns include at least:</li> <li><code>sucursal</code> (branch name)</li> <li><code>fecha</code> (date or datetime)</li> <li>payment method columns (ingreso_efectivo, ingreso_credito, etc.)</li> <li><code>num_tickets</code> (ticket count)</li> <li><code>level</code> (int): QA level to run (default: 4). Controls which checks are executed:</li> <li>Level 0: Schema validation (always run)</li> <li>Level 3: Missing and duplicate days</li> <li>Level 4: Statistical anomalies (z-score)</li> </ul>"},{"location":"api-reference/qa/#returns","title":"Returns","text":"<p>PaymentsQAResult containing: - <code>summary</code>: dictionary with counts and flags - <code>missing_days</code>: DataFrame with missing days per sucursal, or None - <code>duplicate_days</code>: DataFrame with duplicate rows, or None - <code>zscore_anomalies</code>: DataFrame with z-score anomalies, or None - <code>zero_method_flags</code>: DataFrame with zero method flags, or None</p>"},{"location":"api-reference/qa/#raises","title":"Raises","text":"<ul> <li><code>DataQualityError</code>: If required columns are missing.</li> </ul>"},{"location":"api-reference/qa/#example","title":"Example","text":"<pre><code>from pos_core.qa import run_payments_qa\n\nqa_result = run_payments_qa(payments_df, level=4)\n\nprint(f\"Missing days: {qa_result.summary['missing_days_count']}\")\nprint(f\"Anomalies: {qa_result.summary['zscore_anomalies_count']}\")\n\nif qa_result.missing_days is not None:\n    print(qa_result.missing_days)\n</code></pre>"},{"location":"user-guide/concepts/","title":"Concepts","text":"<p>This page explains key concepts and design decisions in POS Core ETL.</p>"},{"location":"user-guide/concepts/#branch-code-windows","title":"Branch Code Windows","text":"<p>Branches (sucursales) may change their codes over time. The package handles this through \"validity windows\" in <code>sucursales.json</code>.</p> <p>Each branch entry can specify: - <code>valid_from</code>: When this code became active - <code>valid_to</code>: When this code became inactive (null if still active)</p> <p>During extraction, the package automatically selects the correct code for each date range based on these windows.</p> <p>Example: If a branch changed codes on 2024-06-01, you'd have two entries:</p> <pre><code>{\n  \"MyBranch\": [\n    {\n      \"code\": \"1234\",\n      \"valid_from\": \"2024-01-01\",\n      \"valid_to\": \"2024-05-31\"\n    },\n    {\n      \"code\": \"5678\",\n      \"valid_from\": \"2024-06-01\",\n      \"valid_to\": null\n    }\n  ]\n}\n</code></pre>"},{"location":"user-guide/concepts/#etl-directory-convention","title":"ETL Directory Convention","text":"<p>The package uses a three-stage directory structure:</p> <ul> <li><code>a_raw/</code>: Raw data files downloaded from POS API (Excel files)</li> <li><code>b_clean/</code>: Cleaned and normalized data (CSV files)</li> <li><code>c_processed/</code>: Aggregated and processed datasets (CSV files)</li> </ul> <p>This convention makes it easy to: - Identify which stage each file belongs to - Re-run specific stages without re-processing everything - Debug issues at each stage</p>"},{"location":"user-guide/concepts/#payments-vs-sales","title":"Payments vs Sales","text":"<p>The package provides two levels of APIs:</p>"},{"location":"user-guide/concepts/#payments-high-level-api","title":"Payments (High-Level API)","text":"<p>The payments API is the primary public interface:</p> <ul> <li><code>build_payments_dataset()</code>: Complete ETL orchestration</li> <li><code>run_payments_forecast()</code>: Forecasting</li> <li><code>run_payments_qa()</code>: Quality assurance</li> </ul> <p>This is the recommended way to work with payment data.</p>"},{"location":"user-guide/concepts/#sales-low-level-utilities","title":"Sales (Low-Level Utilities)","text":"<p>The sales API provides lower-level utilities:</p> <ul> <li>Direct access to extraction functions</li> <li>Manual cleaning and transformation</li> <li>Fine-grained control over the pipeline</li> </ul> <p>Use this when you need more control or are working with sales detail data (which doesn't have a high-level API yet).</p>"},{"location":"user-guide/concepts/#pos-system-requirements","title":"POS System Requirements","text":"<p>This package is designed for POS systems that:</p> <ol> <li>Expose HTTP exports for:</li> <li>Payment reports</li> <li>Sales detail reports</li> <li> <p>Transfer reports</p> </li> <li> <p>Use Excel format for exported reports</p> </li> <li> <p>Support authentication via username/password (optional)</p> </li> </ol> <p>The package is currently optimized for Wansoft-style POS systems, but the architecture allows for future extension to other POS backends.</p>"},{"location":"user-guide/concepts/#incremental-processing","title":"Incremental Processing","text":"<p>The ETL pipeline is designed for incremental processing:</p> <ul> <li>Smart date range chunking: Automatically splits large date ranges into manageable chunks</li> <li>Existing data discovery: Skips downloading files that already exist</li> <li>Resumable: Can be interrupted and resumed without losing progress</li> </ul> <p>This makes it practical to process years of historical data.</p>"},{"location":"user-guide/concepts/#forecasting-model","title":"Forecasting Model","text":"<p>The forecasting module uses ARIMA (AutoRegressive Integrated Moving Average) models:</p> <ul> <li>Log transformation: Applied to handle non-negative values</li> <li>Automatic hyperparameter selection: Searches for optimal ARIMA parameters</li> <li>Per-branch, per-metric: Separate models for each combination</li> </ul> <p>The models require at least 30 days of historical data to generate reliable forecasts.</p>"},{"location":"user-guide/configuration/","title":"Configuration","text":""},{"location":"user-guide/configuration/#branch-configuration-sucursalesjson","title":"Branch Configuration (sucursales.json)","text":"<p>The <code>sucursales.json</code> file maps branch names to codes and tracks validity windows.</p> <p>Default location: <code>utils/sucursales.json</code> (relative to your data root's parent directory)</p> <p>Example structure:</p> <pre><code>{\n  \"Banana\": {\n    \"code\": \"8888\",\n    \"valid_from\": \"2024-02-21\",\n    \"valid_to\": null\n  },\n  \"Queen\": {\n    \"code\": \"6362\",\n    \"valid_from\": \"2024-01-01\",\n    \"valid_to\": null\n  }\n}\n</code></pre>"},{"location":"user-guide/configuration/#fields","title":"Fields","text":"<ul> <li><code>code</code>: Branch code used by the POS system</li> <li><code>valid_from</code>: Date when this code became active (YYYY-MM-DD format)</li> <li><code>valid_to</code>: Date when this code became inactive (null if still active)</li> </ul>"},{"location":"user-guide/configuration/#environment-variables","title":"Environment Variables","text":"<p>Required for online extraction (downloading data from POS API):</p> <ul> <li><code>WS_BASE</code> (required): Base URL of your POS instance</li> <li><code>WS_USER</code> (optional): Username for authentication</li> <li><code>WS_PASS</code> (optional): Password for authentication</li> </ul> <p>Note: These are only needed if you're downloading data from the POS API. If you only work with already-downloaded files, you can ignore these.</p>"},{"location":"user-guide/configuration/#directory-structure","title":"Directory Structure","text":"<p>The package follows an ETL naming convention:</p> <pre><code>data/\n\u251c\u2500\u2500 a_raw/          # Raw data files downloaded from POS API\n\u2502   \u251c\u2500\u2500 payments/\n\u2502   \u2502   \u2514\u2500\u2500 batch/\n\u2502   \u2514\u2500\u2500 sales/\n\u2502       \u2514\u2500\u2500 batch/\n\u251c\u2500\u2500 b_clean/        # Cleaned and normalized data files\n\u2502   \u251c\u2500\u2500 payments/\n\u2502   \u2502   \u2514\u2500\u2500 batch/\n\u2502   \u2514\u2500\u2500 sales/\n\u2502       \u2514\u2500\u2500 batch/\n\u2514\u2500\u2500 c_processed/    # Aggregated and processed datasets\n    \u251c\u2500\u2500 payments/\n    \u2514\u2500\u2500 sales/\n</code></pre>"},{"location":"user-guide/configuration/#etl-configuration","title":"ETL Configuration","text":"<pre><code>from pathlib import Path\nfrom pos_core.etl import PaymentsETLConfig\n\n# Default configuration\nconfig = PaymentsETLConfig.from_data_root(\n    data_root=Path(\"data\"),\n    sucursales_json=Path(\"utils/sucursales.json\"),\n    chunk_size_days=180  # Maximum days per HTTP request\n)\n\n# Custom configuration\nfrom pos_core.etl import PaymentsPaths\n\ncustom_paths = PaymentsPaths(\n    raw_payments=Path(\"custom/raw\"),\n    clean_payments=Path(\"custom/clean\"),\n    proc_payments=Path(\"custom/processed\"),\n    sucursales_json=Path(\"custom/sucursales.json\")\n)\n\nconfig = PaymentsETLConfig(\n    paths=custom_paths,\n    chunk_size_days=90,\n    excluded_branches=[\"CEDIS\"]\n)\n</code></pre>"},{"location":"user-guide/configuration/#forecasting-configuration","title":"Forecasting Configuration","text":"<pre><code>from pos_core.forecasting import ForecastConfig\n\n# Default (7 days, all metrics, all branches)\nconfig = ForecastConfig()\n\n# Custom configuration\nconfig = ForecastConfig(\n    horizon_days=14,\n    metrics=[\"ingreso_efectivo\", \"ingreso_total\"],\n    branches=[\"Banana\", \"Queen\"]\n)\n</code></pre>"},{"location":"user-guide/examples/","title":"Examples","text":"<p>This package includes three runnable example scripts in the <code>examples/</code> directory.</p>"},{"location":"user-guide/examples/#example-1-sales-detail-etl","title":"Example 1: Sales Detail ETL","text":"<p>File: <code>examples/sales_week_by_group.py</code></p> <p>Demonstrates low-level APIs for sales detail ETL:</p> <ul> <li>Downloads sales detail reports for a specific week</li> <li>Cleans Excel files to CSV</li> <li>Aggregates by ticket and by product group</li> <li>Creates a pivot table (groups \u00d7 sucursales)</li> </ul> <p>Usage:</p> <pre><code>python examples/sales_week_by_group.py\n</code></pre> <p>Note: Modify <code>week_start</code> and <code>week_end</code> variables in the script.</p>"},{"location":"user-guide/examples/#example-2-payments-etl","title":"Example 2: Payments ETL","text":"<p>File: <code>examples/payments_full_etl.py</code></p> <p>Demonstrates the high-level payments ETL API:</p> <ul> <li>Downloads payment reports (if needed)</li> <li>Cleans and aggregates payments data</li> <li>Creates daily aggregated dataset</li> <li>Uses <code>build_payments_dataset()</code> - the primary public API</li> </ul> <p>Usage:</p> <pre><code>python examples/payments_full_etl.py\n</code></pre> <p>Note: Modify date range in the script if needed.</p>"},{"location":"user-guide/examples/#example-3-forecasting","title":"Example 3: Forecasting","text":"<p>File: <code>examples/payments_forecast.py</code></p> <p>Demonstrates the forecasting API:</p> <ul> <li>Loads aggregated payments data</li> <li>Generates 7-day forecasts for all branches and metrics</li> <li>Creates deposit schedule for cash flow planning</li> <li>Uses <code>run_payments_forecast()</code> - the forecasting API</li> </ul> <p>Usage:</p> <pre><code>python examples/payments_forecast.py\n</code></pre> <p>Note: Requires running <code>payments_full_etl.py</code> first (or having the aggregated CSV file).</p>"},{"location":"user-guide/examples/#prerequisites","title":"Prerequisites","text":"<p>Before running any example:</p> <ol> <li>Install the package: <code>pip install -e .</code></li> <li>Create <code>utils/sucursales.json</code> (see Configuration)</li> <li>Set <code>WS_BASE</code> environment variable (for online extraction)</li> <li>Create data directory structure (or modify paths in scripts)</li> </ol> <p>See <code>examples/README.md</code> for more details.</p>"},{"location":"user-guide/installation/","title":"Installation","text":""},{"location":"user-guide/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10 or higher</li> <li>POS system with Wansoft-style HTTP exports (see Concepts for details)</li> </ul>"},{"location":"user-guide/installation/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install pos-core-etl\n</code></pre>"},{"location":"user-guide/installation/#install-for-development","title":"Install for Development","text":"<pre><code>git clone https://github.com/ToxicFyre/pos-pipeline-core-etl.git\ncd pos-pipeline-core-etl\npip install -e .[dev]\n</code></pre>"},{"location":"user-guide/installation/#dependencies","title":"Dependencies","text":"<p>The package requires: - pandas &gt;= 1.3.0 - numpy &gt;= 1.20.0 - requests &gt;= 2.25.0 - beautifulsoup4 &gt;= 4.9.0 - statsmodels &gt;= 0.12.0 - openpyxl &gt;= 3.0.0</p> <p>Optional dependencies (for development): - pytest &gt;= 7.0 - mypy &gt;= 1.0.0 - ruff &gt;= 0.1.0 - black &gt;= 23.0.0</p>"},{"location":"user-guide/installation/#next-steps","title":"Next Steps","text":"<ol> <li>Create your <code>sucursales.json</code> configuration file (see Configuration)</li> <li>Set up your data directory structure (see Concepts)</li> <li>Try the Quickstart guide</li> </ol>"},{"location":"user-guide/quickstart/","title":"Quickstart","text":"<p>Get started with POS Core ETL in minutes.</p>"},{"location":"user-guide/quickstart/#basic-etl-workflow","title":"Basic ETL Workflow","text":"<pre><code>from pathlib import Path\nfrom pos_core.etl import PaymentsETLConfig, build_payments_dataset\n\n# Configure\nconfig = PaymentsETLConfig.from_data_root(Path(\"data\"))\n\n# Run ETL for a date range\npayments = build_payments_dataset(\n    start_date=\"2025-01-01\",\n    end_date=\"2025-01-31\",\n    config=config\n)\n\nprint(f\"Processed {len(payments)} rows\")\n</code></pre>"},{"location":"user-guide/quickstart/#forecasting","title":"Forecasting","text":"<pre><code>from pos_core.forecasting import ForecastConfig, run_payments_forecast\n\n# Generate 7-day forecast\nforecast = run_payments_forecast(\n    payments,\n    ForecastConfig(horizon_days=7)\n)\n\nprint(forecast.forecast.head())\n</code></pre>"},{"location":"user-guide/quickstart/#quality-assurance","title":"Quality Assurance","text":"<pre><code>from pos_core.qa import run_payments_qa\n\n# Run QA checks\nqa_result = run_payments_qa(payments)\n\nprint(f\"Missing days: {qa_result.summary['missing_days_count']}\")\nprint(f\"Anomalies: {qa_result.summary['zscore_anomalies_count']}\")\n</code></pre>"},{"location":"user-guide/quickstart/#see-also","title":"See Also","text":"<ul> <li>Configuration - Detailed configuration options</li> <li>Examples - Complete runnable examples</li> <li>API Reference - Full API documentation</li> </ul>"}]}